{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278f148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from balanced_loss import Loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "\n",
    "from data.constants import LOCAL_MODELS_PATH, CHECKPOINTS_PATH, TEST_DF_PATH, LOCAL_MODEL_OUTPUT_FILES_PATH\n",
    "\n",
    "\n",
    "BASE_MODEL_PATH = LOCAL_MODELS_PATH / 't5-small'\n",
    "MAX_LEN = 512\n",
    "batch_size = 8\n",
    "TEST_BATCH_SIZE = batch_size\n",
    "\n",
    "SEED = 2\n",
    "\n",
    "\n",
    "model_name = BASE_MODEL_PATH.name\n",
    "# CHECKPOINTS_DIR = CHECKPOINTS_PATH / model_name / 'checkpoints_train_v3'\n",
    "CHECKPOINTS_DIR = CHECKPOINTS_PATH / model_name / 'checkpoints_train_v2'\n",
    "\n",
    "CHECKPOINTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "MODEL_TO_SAVE_TEMPLE = 'model-{epoch}-epoch.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6156ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights from c:\\users\\eliza\\graduate_work_rep\\biomol-generator\\model_training\\model_epoch_save\\t5-small\\checkpoints_train_v2\\model-14-epoch.pt\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(BASE_MODEL_PATH)  # Замените на вашу базовую модель\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "saved_models = sorted(CHECKPOINTS_DIR.glob(\"*.pt\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "if saved_models:\n",
    "    latest_model_path = saved_models[0] \n",
    "    print(f\"Loading model weights from {latest_model_path}\")\n",
    "    \n",
    "    # Загрузка весов\n",
    "    model.load_state_dict(torch.load(str(latest_model_path), map_location=DEVICE))\n",
    "    model.eval()  \n",
    "else:\n",
    "    print(\"No saved models found. Starting with random weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0923a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinSeqSmailesDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, input_column, output_column, max_len):\n",
    "        self.max_len = max_len\n",
    "        self.df = df\n",
    "        self.input_column = input_column\n",
    "        self.output_column = output_column\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row[self.input_column],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        labels = self.tokenizer.encode_plus(\n",
    "            row[self.output_column],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': labels['input_ids'].flatten(),\n",
    "        }\n",
    "\n",
    "df_test = pd.read_parquet(TEST_DF_PATH)\n",
    "test_dataset = ProteinSeqSmailesDataset(df_test, tokenizer, 'Target', 'Drug', MAX_LEN)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, generator=torch.manual_seed(SEED), num_workers=0, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90159f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eliza\\anaconda3\\envs\\.graduate_work_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Test: 100%|██████████| 125/125 [12:01<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_and_save_results(model, data_loader, device, tokenizer):\n",
    "    model.eval()\n",
    "    \n",
    "    sequences = []\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    test_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Test\"):\n",
    "  \n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "            labels = batch[\"labels\"]\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            \n",
    "            del batch[\"labels\"]\n",
    "\n",
    "            outputs = model(**batch, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits  \n",
    "            \n",
    "            test_losses.append(loss.item())\n",
    "            \n",
    "            decoded_sequences = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "            \n",
    "            decoded_true_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "            decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "            \n",
    "            sequences.extend(decoded_sequences)\n",
    "            true_labels.extend(decoded_true_labels)\n",
    "            predicted_labels.extend(decoded_preds)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        \"Sequence\": sequences,\n",
    "        \"True_Label\": true_labels,\n",
    "        \"Predicted_Label\": predicted_labels\n",
    "    })\n",
    "    \n",
    "    return np.mean(test_losses), results_df\n",
    "\n",
    "test_loss, results_df = evaluate_and_save_results(model, test_loader, DEVICE, tokenizer)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "\n",
    "results_df.to_csv(LOCAL_MODEL_OUTPUT_FILES_PATH / 't5_v2_test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537f5be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>True_Label</th>\n",
       "      <th>Predicted_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MFIEAIVLALTALILYSVYSVKSFNTTRPTDPPVYPVTVPFLGHIV...</td>\n",
       "      <td>O=C(NCC(c1ccccc1)n1ccnc1)c1ccc(-c2ccc(Cl)cc2)cc1</td>\n",
       "      <td>=C(Oc(C1ccc(c1)c1cccc2c1cccc-c2ccccCl)cccc11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDSSTGPGNTSDCSDPLAQASCSPAPGSWLNLSHVDGNQSDPCGLN...</td>\n",
       "      <td>CN1CC[C@]23c4c5ccc(O)c4O[C@H]2[C@@H](O)CC[C@H]...</td>\n",
       "      <td>CCC[CCNC@H12O1c(c(ccC)ccc[C@H](OC@@]](C)[[C@@]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAAAYLDPNLNHTPNSSTKTHLGTGMERSPGAMERVLKVFHYFESN...</td>\n",
       "      <td>C[C@]12O[C@H](C[C@]1(O)CO)n1c3ccccc3c3c4c(c5c6...</td>\n",
       "      <td>CcC@@12O[C@H](C[C@]1(O)CO)n1c3ccccc3c3c4c(c5c6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MELENIVANSLLLKARQGGYGKKSGRSKKWKEILTLPPVSQCSELR...</td>\n",
       "      <td>CO[C@@H]1[C@H](N(C)C(=O)c2ccccc2)C[C@H]2O[C@]1...</td>\n",
       "      <td>CcC@@H]1[C@H](N(C)C(=O)c2ccccc2)C[C@H]2O[C@]1(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAALSGGGGGGAEPGQALFNGDMEPEAGAGAGAAASSAADPAIPEE...</td>\n",
       "      <td>COc1cc2ncnc(Oc3cccc(NC(=O)Nc4cc(-c5ccccc5)on4)...</td>\n",
       "      <td>Cc1cc2ncnc(Nc3ccc((NC(=O)Nc4cccCc5ccccccn4)c3)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>MDRAPQRQHRASRELLAAKKTHTSQIEVIPCKICGDKSSGIHYGVI...</td>\n",
       "      <td>COc1nc2ccc(C(O)(c3cnnn3C)c3cnc(C)n3C)cc2c(C#N)...</td>\n",
       "      <td>Cc1cc2ccc(C(O)(c3cncn3C)cccnn(C)n3C)cc2c(ClN)c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>MAHVRGLQLPGCLALAALCSLVHSQHVFLAPQQARSLLQRVRRANT...</td>\n",
       "      <td>COCCNC(=O)[C@@H]1CCCN1C(=O)CC(c1ccccc1)c1ccccc1</td>\n",
       "      <td>Cc((=O)cC@@H](CCN2C(=O)[CCC2ccc((1)C1ccccc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>MEGTPAANWSVELDLGSGVPPGEEGNRTAGPPQRNEALARVEVAVL...</td>\n",
       "      <td>CCN1C(=O)CC2(CCCCC2)SSC[C@H](C(=O)N2CCC[C@H]2C...</td>\n",
       "      <td>c(CC(=O)N((CC(2)CC((C@@](Cc=O)N[CCCCCCC@H]2O(=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>MDRAPQRQHRASRELLAAKKTHTSQIEVIPCKICGDKSSGIHYGVI...</td>\n",
       "      <td>COc1nc2ccc(C(O)(c3cnc(C)n3C)c3cnc(C)n3C)cc2c(C...</td>\n",
       "      <td>Cc1cc2ccc(C(O)(c3cnc(C)n3C)cccncnC)n3C)cc2c(Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>MPAAAGDGLLGEPAAPGGGGGAEDAARPAAACEGSFLPAWVSGVPR...</td>\n",
       "      <td>CO[C@@H]1[C@H](N(C)C(=O)c2ccccc2)C[C@H]2O[C@]1...</td>\n",
       "      <td>CcC@@H]1[C@H](N(C)C(=O)c2ccccc2)C[C@H]2O[C@]1(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sequence  \\\n",
       "0    MFIEAIVLALTALILYSVYSVKSFNTTRPTDPPVYPVTVPFLGHIV...   \n",
       "1    MDSSTGPGNTSDCSDPLAQASCSPAPGSWLNLSHVDGNQSDPCGLN...   \n",
       "2    MAAAYLDPNLNHTPNSSTKTHLGTGMERSPGAMERVLKVFHYFESN...   \n",
       "3    MELENIVANSLLLKARQGGYGKKSGRSKKWKEILTLPPVSQCSELR...   \n",
       "4    MAALSGGGGGGAEPGQALFNGDMEPEAGAGAGAAASSAADPAIPEE...   \n",
       "..                                                 ...   \n",
       "995  MDRAPQRQHRASRELLAAKKTHTSQIEVIPCKICGDKSSGIHYGVI...   \n",
       "996  MAHVRGLQLPGCLALAALCSLVHSQHVFLAPQQARSLLQRVRRANT...   \n",
       "997  MEGTPAANWSVELDLGSGVPPGEEGNRTAGPPQRNEALARVEVAVL...   \n",
       "998  MDRAPQRQHRASRELLAAKKTHTSQIEVIPCKICGDKSSGIHYGVI...   \n",
       "999  MPAAAGDGLLGEPAAPGGGGGAEDAARPAAACEGSFLPAWVSGVPR...   \n",
       "\n",
       "                                            True_Label  \\\n",
       "0     O=C(NCC(c1ccccc1)n1ccnc1)c1ccc(-c2ccc(Cl)cc2)cc1   \n",
       "1    CN1CC[C@]23c4c5ccc(O)c4O[C@H]2[C@@H](O)CC[C@H]...   \n",
       "2    C[C@]12O[C@H](C[C@]1(O)CO)n1c3ccccc3c3c4c(c5c6...   \n",
       "3    CO[C@@H]1[C@H](N(C)C(=O)c2ccccc2)C[C@H]2O[C@]1...   \n",
       "4    COc1cc2ncnc(Oc3cccc(NC(=O)Nc4cc(-c5ccccc5)on4)...   \n",
       "..                                                 ...   \n",
       "995  COc1nc2ccc(C(O)(c3cnnn3C)c3cnc(C)n3C)cc2c(C#N)...   \n",
       "996    COCCNC(=O)[C@@H]1CCCN1C(=O)CC(c1ccccc1)c1ccccc1   \n",
       "997  CCN1C(=O)CC2(CCCCC2)SSC[C@H](C(=O)N2CCC[C@H]2C...   \n",
       "998  COc1nc2ccc(C(O)(c3cnc(C)n3C)c3cnc(C)n3C)cc2c(C...   \n",
       "999  CO[C@@H]1[C@H](N(C)C(=O)c2ccccc2)C[C@H]2O[C@]1...   \n",
       "\n",
       "                                       Predicted_Label  \n",
       "0         =C(Oc(C1ccc(c1)c1cccc2c1cccc-c2ccccCl)cccc11  \n",
       "1    CCC[CCNC@H12O1c(c(ccC)ccc[C@H](OC@@]](C)[[C@@]...  \n",
       "2    CcC@@12O[C@H](C[C@]1(O)CO)n1c3ccccc3c3c4c(c5c6...  \n",
       "3    CcC@@H]1[C@H](N(C)C(=O)c2ccccc2)C[C@H]2O[C@]1(...  \n",
       "4    Cc1cc2ncnc(Nc3ccc((NC(=O)Nc4cccCc5ccccccn4)c3)...  \n",
       "..                                                 ...  \n",
       "995  Cc1cc2ccc(C(O)(c3cncn3C)cccnn(C)n3C)cc2c(ClN)c...  \n",
       "996        Cc((=O)cC@@H](CCN2C(=O)[CCC2ccc((1)C1ccccc1  \n",
       "997  c(CC(=O)N((CC(2)CC((C@@](Cc=O)N[CCCCCCC@H]2O(=...  \n",
       "998  Cc1cc2ccc(C(O)(c3cnc(C)n3C)cccncnC)n3C)cc2c(Cl...  \n",
       "999  CcC@@H]1[C@H](N(C)C(=O)c2ccccc2)C[C@H]2O[C@]1(...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6de74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".graduate_work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
